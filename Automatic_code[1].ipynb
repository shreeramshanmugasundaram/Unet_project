{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHtcPxR9ZHCZ"
      },
      "source": [
        "###**Videos to frames**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6BEUTudYyw7"
      },
      "outputs": [],
      "source": [
        "\n",
        "#2chamber video\n",
        "\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "def convert_video_to_frames(input_video_path, output_folder, num_frames=150):\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Get the total number of frames in the video\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate the frame interval to get exactly num_frames frames\n",
        "    frame_interval = max(1, total_frames // num_frames)\n",
        "\n",
        "    # Initialize a counter for naming the frames and a counter for saved frames\n",
        "    frame_counter = 0\n",
        "    saved_frames = 0\n",
        "\n",
        "    # Loop through the video frames\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Only save frames at the calculated interval\n",
        "        if frame_counter % frame_interval == 0:\n",
        "            # Save the frame as an image\n",
        "            frame_path = os.path.join(output_folder, f'frame_{saved_frames:04d}.jpg')\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "\n",
        "            saved_frames += 1\n",
        "\n",
        "            # Break if we have saved num_frames frames\n",
        "            if saved_frames == num_frames:\n",
        "                break\n",
        "\n",
        "        # Increment the frame counter\n",
        "        frame_counter += 1\n",
        "\n",
        "    # Release the video capture object and close all windows\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Usage\n",
        "input_video_path = '/content/drive/MyDrive/all work-BACKUP/automation folder/input/2ch_1.avi'\n",
        "output_folder = '/content/drive/MyDrive/all work-BACKUP/automation folder/frames/2'\n",
        "num_frames = 150\n",
        "convert_video_to_frames(input_video_path, output_folder, num_frames)\n",
        "\n",
        "\n",
        "#4chamber video\n",
        "\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def convert_video_to_frames(input_video_path, output_folder, num_frames=150):\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Get the total number of frames in the video\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate the frame interval to get exactly num_frames frames\n",
        "    frame_interval = max(1, total_frames // num_frames)\n",
        "\n",
        "    # Initialize a counter for naming the frames and a counter for saved frames\n",
        "    frame_counter = 0\n",
        "    saved_frames = 0\n",
        "\n",
        "    # Loop through the video frames\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Only save frames at the calculated interval\n",
        "        if frame_counter % frame_interval == 0:\n",
        "            # Save the frame as an image\n",
        "            frame_path = os.path.join(output_folder, f'frame_{saved_frames:04d}.jpg')\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "\n",
        "            saved_frames += 1\n",
        "\n",
        "            # Break if we have saved num_frames frames\n",
        "            if saved_frames == num_frames:\n",
        "                break\n",
        "\n",
        "        # Increment the frame counter\n",
        "        frame_counter += 1\n",
        "\n",
        "    # Release the video capture object and close all windows\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Usage\n",
        "input_video_path = '/content/drive/MyDrive/all work-BACKUP/automation folder/input/4ch_1.avi'\n",
        "output_folder = '/content/drive/MyDrive/all work-BACKUP/automation folder/frames/4'\n",
        "num_frames = 150\n",
        "convert_video_to_frames(input_video_path, output_folder, num_frames)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9mB2LauZPQz"
      },
      "source": [
        "###**Image Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0HBxjHAgaI3U"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "def apply_bilateral_filter(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Get a list of all files in the input folder\n",
        "    input_files = os.listdir(input_folder)\n",
        "\n",
        "    for filename in input_files:\n",
        "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
        "            # Read the frame\n",
        "            frame_path = os.path.join(input_folder, filename)\n",
        "            img = cv2.imread(frame_path)\n",
        "\n",
        "            # Apply bilateral filter\n",
        "            bilateral = cv2.bilateralFilter(img, d=15, sigmaColor=75, sigmaSpace=75)\n",
        "\n",
        "            # Save the filtered frame to the output folder\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, bilateral)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define input and output folder paths in Google Drive\n",
        "input_folder_path = '/content/drive/MyDrive/all work-BACKUP/automation folder/frames/2'\n",
        "output_folder_path= '/content/drive/MyDrive/all work-BACKUP/automation folder/image processed images/2ch'\n",
        "\n",
        "apply_bilateral_filter(input_folder_path, output_folder_path)\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "def apply_bilateral_filter(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Get a list of all files in the input folder\n",
        "    input_files = os.listdir(input_folder)\n",
        "\n",
        "    for filename in input_files:\n",
        "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
        "            # Read the frame\n",
        "            frame_path = os.path.join(input_folder, filename)\n",
        "            img = cv2.imread(frame_path)\n",
        "\n",
        "            # Apply bilateral filter\n",
        "            bilateral = cv2.bilateralFilter(img, d=15, sigmaColor=75, sigmaSpace=75)\n",
        "\n",
        "            # Save the filtered frame to the output folder\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, bilateral)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define input and output folder paths in Google Drive\n",
        "input_folder_path = '/content/drive/MyDrive/all work-BACKUP/automation folder/frames/4'\n",
        "output_folder_path= '/content/drive/MyDrive/all work-BACKUP/automation folder/image processed images/4ch'\n",
        "\n",
        "apply_bilateral_filter(input_folder_path, output_folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgSRTwuYgwUx"
      },
      "source": [
        "###**Automatic Segmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx1TNKkMgqFE",
        "outputId": "a2a723be-f716-45c1-e65a-3c0803d4e40d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 7s 7s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as keras\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow import argmax\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Utils\n",
        "import h5py\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "\n",
        "#2chamber\n",
        "\n",
        "# Load the pre-trained UNet model\n",
        "model_unet = tf.keras.models.load_model(\"/content/drive/MyDrive/all work-BACKUP/automation folder/model/Unet_model_2ch.hdf5\", compile=False)\n",
        "\n",
        "# Function to process images from the input folder and save segmented masks into the output folder\n",
        "def process_images(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Process each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Check if the file is an image file\n",
        "            # Load the image\n",
        "            img_path = os.path.join(input_folder, filename)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Resize the image to dimensions divisible by 32 and match the expected input shape of the model\n",
        "            resized_img = cv2.resize(img, (384, 384))\n",
        "\n",
        "            # Normalize the image\n",
        "            normalized_img = resized_img.astype(np.float32) / 255.0\n",
        "\n",
        "            # Expand dimensions to add channel dimension\n",
        "            input_img = np.expand_dims(normalized_img, axis=-1)\n",
        "\n",
        "            # Predict mask using the UNet model\n",
        "            prediction = model_unet.predict(np.expand_dims(input_img, axis=0))\n",
        "            predicted_mask = tf.argmax(prediction, axis=-1).numpy().squeeze()\n",
        "\n",
        "            # Save the predicted mask as an image\n",
        "            mask_filename = f\"{os.path.splitext(filename)[0]}_mask.png\"\n",
        "            mask_path = os.path.join(output_folder, mask_filename)\n",
        "            plt.imsave(mask_path, predicted_mask, cmap='gray')\n",
        "\n",
        "\n",
        "# Define the input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/all work-BACKUP/automation folder/image processed images/2ch\"\n",
        "output_folder = \"/content/drive/MyDrive/all work-BACKUP/automation folder/segmented masks/2ch\"\n",
        "\n",
        "# Process images from the input folder and save segmented masks into the output folder\n",
        "process_images(input_folder, output_folder)\n",
        "\n",
        "#4chamber\n",
        "\n",
        "# Load the pre-trained UNet model\n",
        "model_unet = tf.keras.models.load_model(\"/content/drive/MyDrive/all work-BACKUP/automation folder/model/Unet_model_4ch.hdf5\", compile=False)\n",
        "\n",
        "# Function to process images from the input folder and save segmented masks into the output folder\n",
        "def process_images(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Process each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Check if the file is an image file\n",
        "            # Load the image\n",
        "            img_path = os.path.join(input_folder, filename)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Resize the image to dimensions divisible by 32 and match the expected input shape of the model\n",
        "            resized_img = cv2.resize(img, (384, 384))\n",
        "\n",
        "            # Normalize the image\n",
        "            normalized_img = resized_img.astype(np.float32) / 255.0\n",
        "\n",
        "            # Expand dimensions to add channel dimension\n",
        "            input_img = np.expand_dims(normalized_img, axis=-1)\n",
        "\n",
        "            # Predict mask using the UNet model\n",
        "            prediction = model_unet.predict(np.expand_dims(input_img, axis=0))\n",
        "            predicted_mask = tf.argmax(prediction, axis=-1).numpy().squeeze()\n",
        "\n",
        "            # Save the predicted mask as an image\n",
        "            mask_filename = f\"{os.path.splitext(filename)[0]}_mask.png\"\n",
        "            mask_path = os.path.join(output_folder, mask_filename)\n",
        "            plt.imsave(mask_path, predicted_mask, cmap='gray')\n",
        "\n",
        "\n",
        "# Define the input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/all work-BACKUP/automation folder/image processed images/4ch\"\n",
        "output_folder = \"/content/drive/MyDrive/all work-BACKUP/automation folder/segmented masks/4ch\"\n",
        "\n",
        "# Process images from the input folder and save segmented masks into the output folder\n",
        "process_images(input_folder, output_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWiMVcZnhjCc"
      },
      "source": [
        "###**Frame Selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5AZR11SFhmpz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to select end-systolic and end-diastolic frames using frame differencing\n",
        "def select_frames(input_folder_2ch, input_folder_4ch, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Process 2ch frames\n",
        "    process_frames(input_folder_2ch, os.path.join(output_folder, \"2ch\"))\n",
        "\n",
        "    # Process 4ch frames\n",
        "    process_frames(input_folder_4ch, os.path.join(output_folder, \"4ch\"))\n",
        "\n",
        "# Function to process frames in a given input folder\n",
        "def process_frames(input_folder, output_subfolder):\n",
        "    # Create the output subfolder\n",
        "    os.makedirs(output_subfolder, exist_ok=True)\n",
        "\n",
        "    # Get the list of mask files sorted by modification time\n",
        "    mask_files = sorted(os.listdir(input_folder), key=lambda f: os.path.getmtime(os.path.join(input_folder, f)))\n",
        "    num_frames = len(mask_files)\n",
        "\n",
        "    # Calculate frame differences\n",
        "    frame_diffs = []\n",
        "    for i in range(1, num_frames):\n",
        "        prev_frame = cv2.imread(os.path.join(input_folder, mask_files[i-1]), cv2.IMREAD_GRAYSCALE)\n",
        "        curr_frame = cv2.imread(os.path.join(input_folder, mask_files[i]), cv2.IMREAD_GRAYSCALE)\n",
        "        diff = np.mean(np.abs(prev_frame - curr_frame))\n",
        "        frame_diffs.append(diff)\n",
        "\n",
        "    # Find indices of frames with maximum and minimum differences\n",
        "    end_systolic_frame_idx = np.argmax(frame_diffs)\n",
        "    end_diastolic_frame_idx = np.argmin(frame_diffs)\n",
        "\n",
        "    # Copy end-systolic and end-diastolic frames to the output folder\n",
        "    shutil.copy2(os.path.join(input_folder, mask_files[end_systolic_frame_idx]), os.path.join(output_subfolder, f'end_systolic_frame.png'))\n",
        "    shutil.copy2(os.path.join(input_folder, mask_files[end_diastolic_frame_idx]), os.path.join(output_subfolder, f'end_diastolic_frame.png'))\n",
        "\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder_2ch = \"/content/drive/MyDrive/all work-BACKUP/automation folder/segmented masks/2ch\"\n",
        "input_folder_4ch = \"/content/drive/MyDrive/all work-BACKUP/automation folder/segmented masks/4ch\"\n",
        "output_folder = \"/content/drive/MyDrive/all work-BACKUP/automation folder/frames images selected \"\n",
        "\n",
        "# Select end-systolic and end-diastolic frames and save them into output folders\n",
        "select_frames(input_folder_2ch, input_folder_4ch, output_folder)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXQwJoTjATvl"
      },
      "source": [
        "###**Ejection Fraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LervFVpgAYd7",
        "outputId": "ed39ce99-f8e9-489d-c104-318f35ce1a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter gender (male/female): male\n",
            "Enter age = 45\n",
            "Male EF 53.46 %  gives heart condition is normal. \n"
          ]
        }
      ],
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#\n",
        "# Function to preprocess the image\n",
        "def preprocess_image(image):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    return blurred\n",
        "\n",
        "# Function to segment ventricles\n",
        "def segment_ventricles(image):\n",
        "    # Apply thresholding to segment ventricles\n",
        "    _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    # Find contours of segmented regions\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # Sort contours by area and find the largest contour\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    # Create a mask for the largest contour\n",
        "    mask = np.zeros_like(image)\n",
        "    cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
        "    return mask\n",
        "\n",
        "# Function to calculate volume from segmented mask\n",
        "def calculate_volume(mask, pixel_spacing):\n",
        "    # Calculate volume in cubic millimeters (mm^3)\n",
        "    volume = np.sum(mask) * pixel_spacing[0] * pixel_spacing[1] * pixel_spacing[2]\n",
        "    return volume\n",
        "\n",
        "# Function to process and calculate volume for each image\n",
        "def process_and_calculate_volume(image_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "    # Preprocess the image\n",
        "    preprocessed_image = preprocess_image(image)\n",
        "    # Segment ventricles\n",
        "    ventricle_mask = segment_ventricles(preprocessed_image)\n",
        "    # Calculate pixel spacing (assuming isotropic voxels)\n",
        "    pixel_spacing = (1.0, 1.0, 1.0)  # Example pixel spacing in millimeters (x, y, z)\n",
        "    # Calculate volume\n",
        "    volume = calculate_volume(ventricle_mask, pixel_spacing)\n",
        "    return volume\n",
        "\n",
        "# Paths to the images\n",
        "four_chamber_systole_path = '/content/drive/MyDrive/all work-BACKUP/automation folder/frames images selected /4ch/end_systolic_frame.png'\n",
        "two_chamber_systole_path = '/content/drive/MyDrive/all work-BACKUP/automation folder/frames images selected /2ch/end_systolic_frame.png'\n",
        "\n",
        "# Process and calculate volumes for each image\n",
        "four_chamber_systole_volume = process_and_calculate_volume(four_chamber_systole_path)\n",
        "two_chamber_systole_volume = process_and_calculate_volume(two_chamber_systole_path)\n",
        "\n",
        "# Print the calculated volumes\n",
        "ESV=(two_chamber_systole_volume+four_chamber_systole_volume)//2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Function to preprocess the image\n",
        "def preprocess_image(image):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    return blurred\n",
        "\n",
        "# Function to segment ventricles\n",
        "def segment_ventricles(image):\n",
        "    # Apply thresholding to segment ventricles\n",
        "    _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    # Find contours of segmented regions\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # Sort contours by area and find the largest contour\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    # Create a mask for the largest contour\n",
        "    mask = np.zeros_like(image)\n",
        "    cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
        "    return mask\n",
        "\n",
        "# Function to calculate volume from segmented mask\n",
        "def calculate_volume(mask, pixel_spacing):\n",
        "    # Calculate volume in cubic millimeters (mm^3)\n",
        "    volume = np.sum(mask) * pixel_spacing[0] * pixel_spacing[1] * pixel_spacing[2]\n",
        "    return volume\n",
        "\n",
        "# Function to process and calculate volume for each image\n",
        "def process_and_calculate_volume(image_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "    # Preprocess the image\n",
        "    preprocessed_image = preprocess_image(image)\n",
        "    # Segment ventricles\n",
        "    ventricle_mask = segment_ventricles(preprocessed_image)\n",
        "    # Calculate pixel spacing (assuming isotropic voxels)\n",
        "    pixel_spacing = (1.2, 1.2, 1.2)  # Example pixel spacing in millimeters (x, y, z)\n",
        "    # Calculate volume\n",
        "    volume = calculate_volume(ventricle_mask, pixel_spacing)\n",
        "    return volume\n",
        "\n",
        "# Paths to the images\n",
        "four_chamber_diastole_path = '/content/drive/MyDrive/all work-BACKUP/automation folder/frames images selected /4ch/end_diastolic_frame.png'\n",
        "two_chamber_diastole_path = '/content/drive/MyDrive/all work-BACKUP/automation folder/frames images selected /2ch/end_diastolic_frame.png'\n",
        "\n",
        "# Process and calculate volumes for each image\n",
        "four_chamber_diastole_volume = process_and_calculate_volume(four_chamber_diastole_path)\n",
        "two_chamber_diastole_volume = process_and_calculate_volume(two_chamber_diastole_path)\n",
        "\n",
        "# Print the calculated volumes\n",
        "EDV=(two_chamber_diastole_volume+four_chamber_diastole_volume)//2\n",
        "\n",
        "EF=((EDV-ESV)/EDV)*100\n",
        "EF=round(EF,2)\n",
        "\n",
        "\n",
        "gender = input(\"Enter gender (male/female): \").lower()\n",
        "age=int(input(\"Enter age = \"))\n",
        "male_ef_ranges = {\n",
        "    \"Normal\": (52, 72),\n",
        "    \"Mildly Reduced\": (41, 51),\n",
        "    \"Moderately Reduced\": (30, 40),\n",
        "    \"Severely Reduced\": (0, 30)\n",
        "}\n",
        "\n",
        "female_ef_ranges = {\n",
        "    \"Normal\": (54, 75),\n",
        "    \"Mildly Reduced\": (41, 53),\n",
        "    \"Moderately Reduced\": (30, 40),\n",
        "    \"Severely Reduced\": (0, 30)\n",
        "}\n",
        "\n",
        "if gender == \"male\":\n",
        "    if EF >= male_ef_ranges[\"Normal\"][0] and EF <= male_ef_ranges[\"Normal\"][1]:\n",
        "        print(\"Male EF\",EF,\"%\",\" gives heart condition is normal. \")\n",
        "    elif EF >= male_ef_ranges[\"Mildly Reduced\"][0] and EF <= male_ef_ranges[\"Mildly Reduced\"][1]:\n",
        "        print(\"Male EF\",EF,\"%\",\" gives heart condition is Mildly abnormal. \")\n",
        "    elif EF >= male_ef_ranges[\"Moderately Reduced\"][0] and EF <= male_ef_ranges[\"Moderately Reduced\"][1]:\n",
        "        print(\"Male EF\",EF,\"%\",\" gives heart condition is Moderately abnormal. \")\n",
        "    else:\n",
        "        print(\"Male EF\",EF,\"%\",\" gives heart condition is Severe. \")\n",
        "\n",
        "elif gender == \"female\":\n",
        "    if EF >= female_ef_ranges[\"Normal\"][0] and EF <= female_ef_ranges[\"Normal\"][1]:\n",
        "        print(\"Female EF\",EF,\"%\",\"gives heart condition is Normal\")\n",
        "    elif EF >= female_ef_ranges[\"Mildly Reduced\"][0] and EF <= female_ef_ranges[\"Mildly Reduced\"][1]:\n",
        "        print(\"Female EF\",EF,\"%\",\"gives heart condition is Mildy Abnormal\")\n",
        "    elif EF >= female_ef_ranges[\"Moderately Reduced\"][0] and EF <= female_ef_ranges[\"Moderately Reduced\"][1]:\n",
        "        print(\"Female EF\",EF,\"%\",\"gives heart condition is Moderately Abnormal\")\n",
        "    else:\n",
        "        print(\"Female EF\",EF,\"%\",\"gives heart condition is Severe\")\n",
        "else:\n",
        "    print(\"Invalid input. Please enter 'male' or 'female' as the gender.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIGDQXr3mnhk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}